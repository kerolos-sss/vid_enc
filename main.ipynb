{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kerolos-sss/vid_enc/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF6YbW90yEEH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPQj-ynTw-V2"
      },
      "source": [
        "trying a video\n",
        "https://www.learningcontainer.com/download/sample-mp4-file/?wpdmdl=2518&refresh=6055d07a6a6031616236666"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHKo7TKXw9or",
        "outputId": "1e97f60b-5a12-4585-edfa-baf0e3b64dd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# !pip install -U kora\n",
        "# from kora.drive import upload_public\n",
        "# url = upload_public('video.mp4')\n",
        "# then display it\n",
        "url = \"\"\"https://www.learningcontainer.com/download/sample-mp4-file/?wpdmdl=2518&refresh=6055d07a6a6031616236666\"\"\"\n",
        "from IPython.display import HTML\n",
        "HTML(f\"\"\"<video src={url} width=500 controls/>\"\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video src=https://www.learningcontainer.com/download/sample-mp4-file/?wpdmdl=2518&refresh=6055d07a6a6031616236666 width=500 controls/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V120cjs5p-hs"
      },
      "source": [
        "Those are just tests "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP-sHfzSo_0S"
      },
      "source": [
        "print(\"hello\")\n",
        "# -*- coding: utf-8 -*-\n",
        "import random\n",
        "import torch\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "# mathematical constants\n",
        "print(np.pi)\n",
        "print(np.e)\n",
        "\n",
        "# trignometric functions\n",
        "angle = np.pi/4\n",
        "print(np.sin(angle))\n",
        "print(np.cos(angle))\n",
        "print(np.tan(angle))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DynamicNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        In the constructor we instantiate five parameters and assign them as members.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.a = torch.nn.Parameter(torch.randn(()))\n",
        "        self.b = torch.nn.Parameter(torch.randn(()))\n",
        "        self.c = torch.nn.Parameter(torch.randn(()))\n",
        "        self.d = torch.nn.Parameter(torch.randn(()))\n",
        "        self.e = torch.nn.Parameter(torch.randn(()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        For the forward pass of the model, we randomly choose either 4, 5\n",
        "        and reuse the e parameter to compute the contribution of these orders.\n",
        "\n",
        "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
        "        Python control-flow operators like loops or conditional statements when\n",
        "        defining the forward pass of the model.\n",
        "\n",
        "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
        "        times when defining a computational graph.\n",
        "        \"\"\"\n",
        "        y = self.a + self.b * x + self.c * x ** 2 + self.d * x ** 3\n",
        "        for exp in range(4, random.randint(4, 6)):\n",
        "            y = y + self.e * x ** exp\n",
        "        return y\n",
        "\n",
        "    def string(self):\n",
        "        \"\"\"\n",
        "        Just like any class in Python, you can also define custom method on PyTorch modules\n",
        "        \"\"\"\n",
        "        return f'y = {self.a.item()} + {self.b.item()} x + {self.c.item()} x^2 + {self.d.item()} x^3 + {self.e.item()} x^4 ? + {self.e.item()} x^5 ?'\n",
        "\n",
        "\n",
        "# Create Tensors to hold input and outputs.\n",
        "x = torch.linspace(-math.pi, math.pi, 2000)\n",
        "y = torch.sin(x)\n",
        "\n",
        "# Construct our model by instantiating the class defined above\n",
        "model = DynamicNet()\n",
        "\n",
        "# Construct our loss function and an Optimizer. Training this strange model with\n",
        "# vanilla stochastic gradient descent is tough, so we use momentum\n",
        "criterion = torch.nn.MSELoss(reduction='sum')\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)\n",
        "for t in range(30000):\n",
        "    # Forward pass: Compute predicted y by passing x to the model\n",
        "    y_pred = model(x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = criterion(y_pred, y)\n",
        "    if t % 2000 == 1999:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Zero gradients, perform a backward pass, and update the weights.\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'Result: {model.string()}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}